{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Interact with Spark Environment\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.2742563Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:11.3758984Z",
              "execution_finish_time": "2022-01-30T20:09:11.9011238Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Brotli 1.0.9\nCython 0.29.23\nFlask 2.0.1\nFlask-Compress 0.0.0\nGitPython 3.1.18\nJinja2 3.0.1\nKeras-Applications 1.0.8\nKeras-Preprocessing 1.1.2\nKqlmagicCustom 0.1.114.post8\nMarkdown 3.3.4\nMarkupSafe 2.0.1\nPillow 8.2.0\nPyGObject 3.40.1\nPyJWT 2.1.0\nPyQt5 5.12.3\nPyQt5-sip 4.19.18\nPyQtChart 5.12\nPyQtWebEngine 5.12.1\nPySocks 1.7.1\nPyWavelets 1.1.1\nPyYAML 5.4.1\nPygments 2.9.0\nSALib 1.3.11\nSQLAlchemy 1.4.20\nSecretStorage 3.3.1\nSend2Trash 1.8.0\nWerkzeug 2.0.1\nabsl-py 0.13.0\nadal 1.2.7\nadlfs 0.7.7\naiohttp 3.7.4.post0\nappdirs 1.4.4\napplicationinsights 0.11.10\nargon2-cffi 21.3.0\nargon2-cffi-bindings 21.2.0\nastor 0.8.1\nastunparse 1.6.3\nasync-timeout 3.0.1\nattrs 21.2.0\nazure-common 1.1.27\nazure-core 1.21.1\nazure-datalake-store 0.0.51\nazure-graphrbac 0.61.1\nazure-identity 1.5.0\nazure-mgmt-authorization 0.61.0\nazure-mgmt-containerregistry 8.0.0\nazure-mgmt-core 1.3.0\nazure-mgmt-keyvault 2.2.0\nazure-mgmt-resource 13.0.0\nazure-mgmt-storage 11.2.0\nazure-storage-blob 12.8.1\nazure-synapse-ml-predict 1.0.0\nazureml-core 1.34.0\nazureml-dataprep 2.22.2\nazureml-dataprep-native 38.0.0\nazureml-dataprep-rslex 1.20.2\nazureml-dataset-runtime 1.34.0\nazureml-mlflow 1.34.0\nazureml-opendatasets 1.34.0\nazureml-telemetry 1.34.0\nbackcall 0.2.0\nbackports.functools-lru-cache 1.6.4\nbackports.tempfile 1.0\nbackports.weakref 1.0.post1\nbeautifulsoup4 4.9.3\nbleach 4.1.0\nblinker 1.4\nbokeh 2.3.2\nbrotlipy 0.7.0\ncachetools 4.2.2\ncertifi 2021.5.30\ncffi 1.14.5\nchardet 4.0.0\nclick 8.0.1\ncloudpickle 1.6.0\nconda-package-handling 1.7.3\nconfigparser 5.0.2\ncontextlib2 0.6.0.post1\ncryptography 3.4.7\ncycler 0.10.0\ncytoolz 0.11.0\ndash 1.20.0\ndash-core-components 1.16.0\ndash-cytoscape 0.2.0\ndash-html-components 1.1.3\ndash-renderer 1.9.1\ndash-table 4.11.3\ndask 2021.6.2\ndatabricks-cli 0.12.1\ndebugpy 1.3.0\ndecorator 4.4.2\ndefusedxml 0.7.1\ndill 0.3.4\ndistro 1.6.0\ndocker 4.4.4\ndotnetcore2 2.1.22\nentrypoints 0.3\net-xmlfile 1.1.0\nfire 0.4.0\nflatbuffers 1.12\nfsspec 2021.6.1\nfsspec-wrapper 1.0.0\nfusepy 3.0.1\nfuture 0.18.2\ngast 0.3.3\ngensim 3.8.3\ngeographiclib 1.52\ngeopy 2.1.0\ngevent 21.1.2\ngitdb 4.0.7\ngoogle-auth 1.32.1\ngoogle-auth-oauthlib 0.4.1\ngoogle-pasta 0.2.0\ngraphframes 0.6\ngreenlet 1.1.0\ngrpcio 1.37.1\nh5py 2.10.0\nhtml5lib 1.1\nhummingbird-ml 0.4.0\nidna 2.10\nimagecodecs 2021.3.31\nimageio 2.9.0\nimportlib-metadata 4.6.1\nimportlib-resources 5.4.0\nipykernel 6.0.1\nipython 7.23.1\nipython-genutils 0.2.0\nipywidgets 7.6.3\nisodate 0.6.0\nitsdangerous 2.0.1\njdcal 1.4.1\njedi 0.18.0\njeepney 0.6.0\njmespath 0.10.0\njoblib 1.0.1\njsonpickle 2.0.0\njsonschema 4.4.0\njupyter-client 6.1.12\njupyter-core 4.7.1\njupyterlab-pygments 0.1.2\njupyterlab-widgets 1.0.2\nkeras2onnx 1.6.5\nkiwisolver 1.3.1\nkoalas 1.8.0\nliac-arff 2.5.0\nlibrary-metadata-cooker 0.0.7\nlightgbm 3.2.1\nlime 0.2.0.1\nllvmlite 0.36.0\nlocket 0.2.1\nlxml 4.6.5\nmatplotlib 3.4.2\nmatplotlib-inline 0.1.2\nmistune 0.8.4\nmleap 0.17.0\nmlflow-skinny 1.18.0\nmmlspark-cognitive 1.0.0.dev1\nmmlspark-core 1.0.0.dev1\nmmlspark-lightgbm 1.0.0.dev1\nmmlspark-opencv 1.0.0.dev1\nmmlspark-vw 1.0.0.dev1\nmsal 1.12.0\nmsal-extensions 0.3.0\nmsrest 0.6.21\nmsrestazure 0.6.4\nmultidict 5.1.0\nmypy 0.780\nmypy-extensions 0.4.3\nnbclient 0.5.10\nnbconvert 6.4.0\nnbformat 5.1.3\nndg-httpsclient 0.5.1\nnest-asyncio 1.5.4\nnetworkx 2.5.1\nnltk 3.6.2\nnose 1.3.7\nnotebook 6.4.7\nnotebookutils 3.1.2-20220115.5\nnumba 0.53.1\nnumpy 1.19.4\noauthlib 3.1.1\nolefile 0.46\nonnx 1.9.0\nonnxconverter-common 1.7.0\nonnxmltools 1.7.0\nonnxruntime 1.7.2\nopenpyxl 3.0.7\nopt-einsum 3.3.0\npackaging 21.0\npandas 1.2.3\npandasql 0.7.3\npandocfilters 1.5.0\nparso 0.8.2\npartd 1.2.0\npathspec 0.8.1\npatsy 0.5.1\npexpect 4.8.0\npickleshare 0.7.5\npip 21.1.1\nplotly 4.14.3\npmdarima 1.8.2\npooch 1.4.0\nportalocker 1.7.1\nprettytable 2.4.0\nprometheus-client 0.12.0\nprompt-toolkit 3.0.19\nprotobuf 3.15.8\npsutil 5.8.0\nptyprocess 0.7.0\npy4j 0.10.9\npyOpenSSL 20.0.1\npyarrow 3.0.0\npyasn1 0.4.8\npyasn1-modules 0.2.8\npycairo 1.20.1\npycosat 0.6.3\npycparser 2.20\npyodbc 4.0.30\npyparsing 2.4.7\npyperclip 1.8.2\npyrsistent 0.18.1\npyspark 3.1.2\npython-dateutil 2.8.1\npytz 2021.1\npyu2f 0.1.5\npyzmq 22.1.0\nregex 2021.7.6\nrequests 2.25.1\nrequests-oauthlib 1.3.0\nretrying 1.3.3\nrsa 4.7.2\nruamel-yaml-conda 0.15.100\nruamel.yaml 0.17.4\nruamel.yaml.clib 0.2.6\nscikit-image 0.18.1\nscikit-learn 0.23.2\nscipy 1.5.3\nseaborn 0.11.1\nsetuptools 49.6.0.post20210108\nshap 0.39.0\nsix 1.16.0\nskl2onnx 1.8.0\nsklearn-pandas 2.2.0\nslicer 0.0.7\nsmart-open 5.1.0\nsmmap 3.0.5\nsoupsieve 2.2.1\nstatsmodels 0.12.2\ntabulate 0.8.9\ntenacity 7.0.0\ntensorboard 2.4.1\ntensorboard-plugin-wit 1.8.0\ntensorflow 2.4.1\ntensorflow-estimator 2.4.0\ntermcolor 1.1.0\nterminado 0.12.1\ntestpath 0.5.0\ntextblob 0.15.3\nthreadpoolctl 2.1.0\ntifffile 2021.4.8\ntoolz 0.11.1\ntorch 1.8.1\ntorchvision 0.9.1\ntornado 6.1\ntqdm 4.61.2\ntraitlets 5.0.5\ntyped-ast 1.4.3\ntyping-extensions 3.10.0.0\nurllib3 1.26.4\nwcwidth 0.2.5\nwebencodings 0.5.1\nwebsocket-client 1.1.0\nwheel 0.36.2\nwidgetsnbextension 3.5.2\nwrapt 1.12.1\nxgboost 1.4.0\nyarl 1.6.3\nzipp 3.5.0\nzope.event 4.5.0\nzope.interface 5.4.0"
        }
      ],
      "metadata": {
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark \n",
        "\n",
        "# Display Installed Packages\n",
        "\n",
        "import pkg_resources\n",
        "pkg_list = list()\n",
        "\n",
        "for d in sorted(pkg_resources.working_set):\n",
        "    pkg_list.append(str(d))\n",
        "for p in sorted(pkg_list):\n",
        "    print(p)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.3371897Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:11.999206Z",
              "execution_finish_time": "2022-01-30T20:09:12.1539809Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pyspark.sql.session.SparkSession'>\n<class 'pyspark.sql.conf.RuntimeConfig'>\nspark version:  3.1.2.5.0-50849917"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "# Display Spark Version\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "sc = SparkSession.builder.getOrCreate() \n",
        "\n",
        "print(str(type(sc)))          # <class 'pyspark.sql.session.SparkSession'>\n",
        "print(str(type(spark.conf)))  # <class 'pyspark.sql.conf.RuntimeConfig'>\n",
        "print('spark version:  {}'.format(sc.version))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.4049756Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:12.2656809Z",
              "execution_finish_time": "2022-01-30T20:09:12.4132025Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "workspace name: cjoakimcslsynapse\nmood: happy"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark \n",
        "\n",
        "# Interact with spark.conf in PySpark\n",
        "\n",
        "print('workspace name: {}'.format(spark.conf.get('spark.synapse.workspace.name')))\n",
        "\n",
        "spark.conf.set(\"mood\", \"happy\")\n",
        "print('mood: {}'.format(spark.conf.get('mood')))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.4478732Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:12.5070248Z",
              "execution_finish_time": "2022-01-30T20:09:15.2568397Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "conf: org.apache.spark.sql.RuntimeConfig = org.apache.spark.sql.RuntimeConfig@2f8b4db6\ncjoakimcslsynapse\nhappy\nthrilled\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark \n",
        "\n",
        "// Interact with spark.conf in Scala\n",
        "\n",
        "val conf = spark.conf \n",
        "\n",
        "println(conf.get(\"spark.synapse.workspace.name\"))\n",
        "println(conf.get(\"mood\"))\n",
        "\n",
        "conf.set(\"mood\", \"thrilled\")\n",
        "println(conf.get(\"mood\"))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.4880663Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:15.3471954Z",
              "execution_finish_time": "2022-01-30T20:09:17.1957465Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 12, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "arrayConfig: Array[(String, String)] = Array((spark.kryo.registrator,com.microsoft.spark.sqlanalytics.utils.MyKryoRegistrator,com.nvidia.spark.rapids.GpuKryoRegistrator), (spark.sparkContextAfterInit.plugins,org.apache.spark.microsoft.tools.api.plugin.MSToolsSparkContextAfterInitPlugin), (spark.databricks.delta.vacuum.parallelDelete.enabled,true), (spark.driver.cores,4), (spark.yarn.containerLauncherMaxThreads,25), (spark.sql.convertInnerJoinToLeftSemiJoin,true), (spark.eventLog.dir,wasbs://ab4ac815-c745-4a9a-85ec-dde7422c3794@139tqgao8koi70i65nhrafwa.blob.core.windows.net/events/23/eventLogs/), (spark.shuffle.io.serverThreads,128), (spark.livy.server.session.timeout,1800000), (spark.hadoop.javax.jdo.option.ConnectionUserName,metastorelogin262335@a365metastoreprodeastus-26.database.wind...\nspark.app.id, application_1643569089932_0002\nspark.app.name, spark_env_poolspark3s_1643573252\nspark.app.startTime, 1643573281151\nspark.appLiveStatusPlugins, org.apache.spark.ui.EnhancementLiveStatusPlugin,org.apache.spark.diagnostic.synapse.SparkDiagnosticPlugin,org.apache.spark.deploy.history.rpc.app.RpcAppLivePlugin\nspark.arcadia.session.token, eyJhbGciOiJodHRwOi8vd3d3LnczLm9yZy8yMDAxLzA0L3htbGRzaWctbW9yZSNyc2Etc2hhMjU2Iiwia2lkIjoiMEZCNzk5NTEwMjI3QkIwMTMxQzFFRjE1NkJBOEE0NzI4RDFGOTU0QyIsInR5cCI6IkpXVCJ9.eyJhdXRoVG9rZW4iOiJBQUVBRkErM21WRUNKN3NCTWNIdkZXdW9wSEtOSDVWTUFRQkJsc1QwOUpBR1h1SVlRUi81UEorOVFXTTM2ck9OOXMxU3RPY0tMc080ZHB1Z0lhYTVMTHJmQmRLa3JIYnZXUjlaSVdhUXhOWC9WNDhEbW5CdlB4TldEWmRwc1RYa3JVVUpzSSt1a1BIbm55UE5xWTNSRUxvV0lKa3ZuTnBFQUwybUxKMThMRUNvYUMrQlZqYzIrOGk5djRqT2I0YTR3bDJIcE9jR0cyNkJ6cGtHVHRyK2FTdzdmSGlRRTZwMEtIUTFpZ1MrbjBEZnlwK3hNWFRGc1Y2eThCblBabFQ5NUNwZVowMzZ1eWdKVG1JcThnSkZtNnFidFgzS2pHb3FtRkREaDRzUk12Nm5HdUdaMGVyeVpiL1lhTXUzbEROZ0FvOGRFblhCbWp1VFdWV2pzdldiSG1BUFlHQ0xkY2pxUmc2bEJWQW1IdWVnVWFjWnhMVTFnaVpuQUJDRmJkMktzVnpiOEd1TW4zcW45WWFSQVdCS2xPS1lDdjhOY2Fuak05SGpGaDhZRmUyRCtSY3E2ZlJGR2Z0WUZzelgwL01NbWtwYVFwWWwrN2p0NkFKaDVHdmxwZ0dieTlHN0RReWNhUFh6ZTRwZDY5Y2hpV2tBVXowQnVERjR4TWowSDc4aGFHRGR4R1JqdUNOMkZKS0pmMVJ2N0IwNWdSZ1lRcVBsbzJzMXhSQmxaQzlFaHlSRll4T2YrQXd3L0paYmN4YkJsLzVLV25OanlMZzdSZDBpdGNHbVBQemxkSzRkS1ZVZkRUeHpWZmtJZkhBSGt3SVJOVDdoNGQzdlZETjRhVlNGbXI5d25lbXIvUjh3L3g4eUNXMEV1bkFCRUU5a0ZPR3Jla3RtTUd0SHBNTDBSY0NhUzJQS05yT2FTZTV6ME5VTkw5M3JZSXo5bUszcmh2UjZsQ29NOGlEaVdWcG1YUnc0UFhwdSs0TE5rQkRDQ01Ka2h5cUdObkkxTElnY1FKc1lrcFphOUQ3dnRVV2xWdFB5Vm5zVithaXREV3lQMTdyemJHMCt5ZmZVRFdvYnBLSVFUMGNOR05hZkxRb3hQSlBTZUhNL1ljTXU3UzVvSUg0ZmM2VEJWUk9QUkNqMjh3T3p3TWVhNnJTUCIsInNpZ25hdHVyZVBheWxvYWQiOnsidXNlcklkIjoiNmYzMTBlY2MtNmY3My00YWVkLWEyY2YtNWQ3YTYwOWZkOTFhIiwiam9iSWQiOiIyMyIsImNsdXN0ZXJJZCI6IjU2ZjczZmI3LTM2NDQtNDRiNC1iMGZhLWJjMmYwNjQyZGZlZCIsIndvcmtzcGFjZU5hbWUiOiJjam9ha2ltY3Nsc3luYXBzZSIsImNvbXB1dGVOYW1lIjoicG9vbHNwYXJrM3MiLCJqb2JUeXBlIjoiU3BhcmtTZXJ2aWNlU2Vzc2lvbiJ9LCJmYWN0b3J5TG9jYXRpb24iOiJlYXN0dXMifQ.hQejpgqYfeuhaCyJbnCfvDhrwoGx47ELB_xKnW8KXpJOtmT4TeH1lM1dpta0M2flFC-oqPfYbhdIpvDEkgQuFoR3wAU1Wq-1s5Tw7SCyN40jm7bqHN7E7x8_16ZuRAiZaKF6kRpwX8fTuwOSd1PcfJY7i7zk0qPBY5wQh_0PUrEj1IBHLPYg6rWYNjeMxayV181b-Txir76ZHt24dm4A7SoG5X2wPfKjYEjFKeWYcvqLgXdPux3c127aoEjxVmTJzyrCC0SZlJ5egbQQ9ZrdFOFTVRj7afCx3Zg5O7CrjhaRJOghOYdmsLgE-xjNHQfrPNVpIp24lwlV0HClTNP70A\nspark.autotune.trackingId, aee6cc7e-eb33-4a49-8ec1-740f695fe8a4\nspark.cluster.environment.name, Arcadia-Cluster-Service-PROD-EastUS\nspark.cluster.environment.type, PROD\nspark.cluster.name, 56f73fb7-3644-44b4-b0fa-bc2f0642dfed\nspark.cluster.node.name, vm-7f587466\nspark.cluster.region, eastus\nspark.databricks.delta.vacuum.parallelDelete.enabled, true\nspark.delta.logStore.class, org.apache.spark.sql.delta.storage.AzureLogStore\nspark.dotnet.nuget.fallbackPackagesPath, /usr/local/lib/sparkdotnet/.nuget/packages\nspark.dotnet.packages, nuget:Microsoft.Spark,2.0.0;nuget:Microsoft.Spark.Extensions.DotNet.Interactive,2.0.0;nuget:Microsoft.Spark.Extensions.Delta,2.0.0;nuget:Microsoft.Spark.Extensions.Hyperspace,2.0.0;nuget:Microsoft.Spark.Extensions.Azure.Synapse.Analytics,0.15.0\nspark.dotnet.shell.command, /usr/share/dotnet-tools/dotnet-interactive,[synapse],stdio,--default-kernel,csharp\nspark.driver.cores, 4\nspark.driver.extraClassPath, /usr/lib/library-manager/bin/libraries/scala/*\nspark.driver.extraJavaOptions, -Detwlogger.component=sparkdriver -DlogFilter.filename=SparkLogFilters.xml -DpatternGroup.filename=SparkPatternGroups.xml -Dlog4jspark.root.logger=INFO,console,RFA,ETW,Anonymizer -Dlog4jspark.log.dir=/var/log/sparkapp/${user.name} -Dlog4jspark.log.file=sparkdriver.log -Dlog4j.configuration=file:/usr/hdp/current/spark3-client/conf/driver-log4j.properties -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -XX:+UseParallelGC -XX:+UseParallelOldGC -XX:+TieredCompilation -XX:Tier4CompileThreshold=150000 -noverify\nspark.driver.extraLibraryPath, /usr/hdp/current/hadoop-client/lib/native:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server\nspark.driver.host, vm-7b077896\nspark.driver.maxResultSize, 4096m\nspark.driver.memory, 28g\nspark.driver.memoryOverhead, 384\nspark.driver.port, 45071\nspark.dynamicAllocation.disableIfMinMaxNotSpecified.enabled, true\nspark.dynamicAllocation.enabled, false\nspark.dynamicAllocation.maxExecutors, 2\nspark.dynamicAllocation.minExecutors, 2\nspark.eventLog.buffer.kb, 4k\nspark.eventLog.dir, wasbs://ab4ac815-c745-4a9a-85ec-dde7422c3794@139tqgao8koi70i65nhrafwa.blob.core.windows.net/events/23/eventLogs/\nspark.eventLog.enabled, true\nspark.executor.cores, 4\nspark.executor.extraClassPath, /usr/lib/library-manager/bin/libraries/scala/*\nspark.executor.extraJavaOptions, -Detwlogger.component=sparkexecutor -DlogFilter.filename=SparkLogFilters.xml -DpatternGroup.filename=SparkPatternGroups.xml -Dlog4jspark.root.logger=INFO,console,RFA,ETW,Anonymizer -Dlog4jspark.log.dir=/var/log/sparkapp/${user.name} -Dlog4jspark.log.file=sparkexecutor.log -Dlog4j.configuration=file:/usr/hdp/current/spark3-client/conf/executor-log4j.properties -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -XX:+UseG1GC\nspark.executor.extraLibraryPath, /usr/hdp/current/hadoop-client/lib/native:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server\nspark.executor.id, driver\nspark.executor.instances, 2\nspark.executor.memory, 28g\nspark.executor.memoryOverhead, 384\nspark.executorEnv.PYTHONPATH, /opt/spark/python/lib/pyspark.zip<CPS>/opt/spark/python/lib/py4j-0.10.7-src.zip<CPS>/opt/spark/python/lib/pyspark.zip<CPS>/opt/spark/python/lib/py4j-0.10.7-src.zip\nspark.executorEnv.SPARK_HOME, /opt/spark\nspark.extraListeners, com.microsoft.hdinsight.spark.metrics.SparkMetricsListener,com.microsoft.peregrine.spark.listeners.PeregrineListenerSynapse,org.apache.spark.listeners.LogAnalyticsSparkListener\nspark.hadoop.fs.azure.block.blob.with.compaction.dir, wasbs://ab4ac815-c745-4a9a-85ec-dde7422c3794@139tqgao8koi70i65nhrafwa.blob.core.windows.net/events/23/eventLogs/\nspark.hadoop.fs.azure.client.correlationid , 511f1936-008e-4d9f-8a5a-150f6cfb57d4\nspark.hadoop.javax.jdo.option.ConnectionDriverName, com.microsoft.sqlserver.jdbc.SQLServerDriver\nspark.hadoop.javax.jdo.option.ConnectionPassword, 9lGelePT7jVVT3FqoTelKglQjYH1mE\nspark.hadoop.javax.jdo.option.ConnectionURL, jdbc:sqlserver://a365metastoreprodeastus-26.database.windows.net:1433;database=workspacemetastore262335;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\nspark.hadoop.javax.jdo.option.ConnectionUserName, metastorelogin262335@a365metastoreprodeastus-26.database.windows.net\nspark.hadoop.mapreduce.fileoutputcommitter.algorithm.version, 2\nspark.history.fs.cleaner.enabled, false\nspark.history.fs.cleaner.interval, 30d\nspark.history.store.path, /var/lib/spark3/shs_db\nspark.history.ui.port, 18080\nspark.inputOutput.data.enabled, true\nspark.io.compression.lz4.blockSize, 128kb\nspark.jarLoadOrder.userJarFirst, true\nspark.kryo.registrator, com.microsoft.spark.sqlanalytics.utils.MyKryoRegistrator,com.nvidia.spark.rapids.GpuKryoRegistrator\nspark.kryoserializer.buffer.max, 128m\nspark.livy.pipeInteractiveConsoleBacktoSparkConsole.enabled, true\nspark.livy.server.session.timeout, 1800000\nspark.livy.session.type, interactive\nspark.livy.spark_major_version, 3\nspark.livy.synapse.sql.displayFormatter.enabled, True\nspark.locality.wait, 1\nspark.master, yarn\nspark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS, vm-7b077896,vm-7f587466\nspark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES, http://vm-7b077896:8088/proxy/application_1643569089932_0002,http://vm-7f587466:8088/proxy/application_1643569089932_0002\nspark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.RM_HA_URLS, vm-7b077896:8088,vm-7f587466:8088\nspark.pythonRunnerOutputStream.plugin, org.apache.spark.microsoft.tools.api.plugin.MSToolsPythonRunnerOutputStreamPlugin\nspark.rapids.sql.concurrentGpuTasks, 2\nspark.rapids.sql.explain, NOT_ON_GPU\nspark.rdd.compress, true\nspark.redaction.regex, (?i)secret|password|session.token\nspark.repl.class.outputDir, /mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/tmp/spark2005198502007934958\nspark.repl.class.uri, spark://vm-7b077896:45071/classes\nspark.serializer, org.apache.spark.serializer.KryoSerializer\nspark.shuffle.file.buffer, 1m\nspark.shuffle.io.backLog, 8192\nspark.shuffle.io.serverThreads, 128\nspark.shuffle.service.client.class, org.apache.spark.network.shuffle.ShuffleMovementAwareExternalBlockStoreClient\nspark.shuffle.service.enabled, true\nspark.shuffle.unsafe.file.output.buffer, 5m\nspark.sparkContextAfterInit.plugins, org.apache.spark.microsoft.tools.api.plugin.MSToolsSparkContextAfterInitPlugin\nspark.sql.autoBroadcastJoinThreshold, 26214400\nspark.sql.bloom.enabled, true\nspark.sql.bnlj.codegen.enabled, true\nspark.sql.cardinalityEstimation.enabled, true\nspark.sql.catalog.spark_catalog, org.apache.spark.sql.delta.catalog.DeltaCatalog\nspark.sql.catalogImplementation, hive\nspark.sql.cbo.enabled, true\nspark.sql.cbo.joinReorder.enabled, true\nspark.sql.convertInnerJoinToLeftSemiJoin, true\nspark.sql.crossJoin.enabled, true\nspark.sql.decimalDivision.optimizationEnabled, true\nspark.sql.dpp.size.estimate, true\nspark.sql.exchange.reuse.correction.enabled, true\nspark.sql.execution.arrow.pyspark.enabled, true\nspark.sql.execution.arrow.pyspark.fallback.enabled, true\nspark.sql.execution.collapseAggregateNodes, true\nspark.sql.execution.pyspark.udf.simplifiedTraceback.enabled, true\nspark.sql.extensions, com.microsoft.vegas.common.VegasExtensionBuilder,io.delta.sql.DeltaSparkSessionExtension,com.microsoft.peregrine.spark.extensions.SparkExtensionsSynapse,com.microsoft.azure.synapse.ml.predict.SynapsePredictExtensions,com.microsoft.ftl.FTLPlugin\nspark.sql.files.maxPartitionBytes, 134217728\nspark.sql.hive.convertMetastoreOrc, true\nspark.sql.hive.metastore.jars, /opt/hive-metastore/lib/*\nspark.sql.hive.metastore.version, 2.3.2\nspark.sql.joinConditionReorder.enabled, true\nspark.sql.legacy.replaceDatabricksSparkAvro.enabled, false\nspark.sql.local.window.optimization.enabled, true\nspark.sql.optimizer.dynamicPartitionPruning.reuseBroadcastOnly, false\nspark.sql.optimizer.dynamicShufflePruning.enabled, true\nspark.sql.orc.filterPushdown, true\nspark.sql.orc.impl, native\nspark.sql.parquet.footerCache.size, 1000\nspark.sql.preaggregation.enabled, true\nspark.sql.preaggregation.partition.key.based.stats.enabled, true\nspark.sql.preaggregation.pushdown.below.union.enabled, true\nspark.sql.pruneFileSourcePartitions.enableStats, true\nspark.sql.sizeBasedJoinReorder.enabled, true\nspark.sql.sources.parallelPartitionDiscovery.parallelism, 200\nspark.sql.statistics.fallBackToHdfs, true\nspark.sql.warehouse.dir, abfss://synapse_acct@cjoakimcslsynapse.dfs.core.windows.net/synapse/workspaces/cjoakimcslsynapse/warehouse\nspark.sql.window.sort.optimization.enabled, true\nspark.sqlanalyticsconnector.stagingdir.prefix, abfss://synapse_acct@cjoakimcslsynapse.dfs.core.windows.net/synapse/workspaces/cjoakimcslsynapse/sparkpools/poolspark3s/sparkpoolinstances/6f310ecc-6f73-4aed-a2cf-5d7a609fd91a/livysessions/2022/01/30/23/tempdata/\nspark.storage.decommission.enabled, true\nspark.storage.decommission.rddBlocks.enabled, true\nspark.storage.decommission.shuffleBlocks.enabled, true\nspark.submit.deployMode, cluster\nspark.submit.pyFiles, local:///opt/spark/python/lib/pyspark.zip,local:///opt/spark/python/lib/py4j-0.10.7-src.zip\nspark.synapse.clusteridentifier, 56f73fb7-3644-44b4-b0fa-bc2f0642dfed\nspark.synapse.context.activityrunid, \nspark.synapse.context.notebookname, spark_env\nspark.synapse.context.pipelinejobid, \nspark.synapse.customercorrelationid, 511f1936-008e-4d9f-8a5a-150f6cfb57d4\nspark.synapse.dep.enabled, false\nspark.synapse.diagnostic.builtinEmitters, ShoeboxEmitter\nspark.synapse.diagnostic.emitter.ShoeboxEmitter.type, Shoebox\nspark.synapse.history.rpc.batch.size, 2000\nspark.synapse.history.rpc.message.maxSize, 10485760\nspark.synapse.history.rpc.port, 18082\nspark.synapse.history.rpc.sparkContext.enabled, true\nspark.synapse.history.rpc.update.delayMs, 2000\nspark.synapse.history.rpc.update.intervalMs, 1000\nspark.synapse.history.rpc.update.retry.maxNumber, 3\nspark.synapse.history.rpc.update.retry.waitMs, 5000\nspark.synapse.history.rpc.update.timeoutMs, 5000\nspark.synapse.history.rpc.waitAppStart.enabled, true\nspark.synapse.jobidentifier, cjoakimcslsynapse.poolspark3s.23\nspark.synapse.nbs.kernelid, df9cd1f8-ffec-44c1-a7a7-87b36d9a7935\nspark.synapse.pool.name, poolspark3s\nspark.synapse.rpc.listener.historyServer.address, ${hadoopconf-yarn.resourcemanager.hostname.rm1}\nspark.synapse.rpc.listener.nodeInfo.enabled, true\nspark.synapse.rpc.listener.nodeInfo.path, /etc/bbc/nodes.json\nspark.synapse.session.token, eyJhbGciOiJodHRwOi8vd3d3LnczLm9yZy8yMDAxLzA0L3htbGRzaWctbW9yZSNyc2Etc2hhMjU2Iiwia2lkIjoiMEZCNzk5NTEwMjI3QkIwMTMxQzFFRjE1NkJBOEE0NzI4RDFGOTU0QyIsInR5cCI6IkpXVCJ9.eyJhdXRoVG9rZW4iOiJBQUVBRkErM21WRUNKN3NCTWNIdkZXdW9wSEtOSDVWTUFRQkJsc1QwOUpBR1h1SVlRUi81UEorOVFXTTM2ck9OOXMxU3RPY0tMc080ZHB1Z0lhYTVMTHJmQmRLa3JIYnZXUjlaSVdhUXhOWC9WNDhEbW5CdlB4TldEWmRwc1RYa3JVVUpzSSt1a1BIbm55UE5xWTNSRUxvV0lKa3ZuTnBFQUwybUxKMThMRUNvYUMrQlZqYzIrOGk5djRqT2I0YTR3bDJIcE9jR0cyNkJ6cGtHVHRyK2FTdzdmSGlRRTZwMEtIUTFpZ1MrbjBEZnlwK3hNWFRGc1Y2eThCblBabFQ5NUNwZVowMzZ1eWdKVG1JcThnSkZtNnFidFgzS2pHb3FtRkREaDRzUk12Nm5HdUdaMGVyeVpiL1lhTXUzbEROZ0FvOGRFblhCbWp1VFdWV2pzdldiSG1BUFlHQ0xkY2pxUmc2bEJWQW1IdWVnVWFjWnhMVTFnaVpuQUJDRmJkMktzVnpiOEd1TW4zcW45WWFSQVdCS2xPS1lDdjhOY2Fuak05SGpGaDhZRmUyRCtSY3E2ZlJGR2Z0WUZzelgwL01NbWtwYVFwWWwrN2p0NkFKaDVHdmxwZ0dieTlHN0RReWNhUFh6ZTRwZDY5Y2hpV2tBVXowQnVERjR4TWowSDc4aGFHRGR4R1JqdUNOMkZKS0pmMVJ2N0IwNWdSZ1lRcVBsbzJzMXhSQmxaQzlFaHlSRll4T2YrQXd3L0paYmN4YkJsLzVLV25OanlMZzdSZDBpdGNHbVBQemxkSzRkS1ZVZkRUeHpWZmtJZkhBSGt3SVJOVDdoNGQzdlZETjRhVlNGbXI5d25lbXIvUjh3L3g4eUNXMEV1bkFCRUU5a0ZPR3Jla3RtTUd0SHBNTDBSY0NhUzJQS05yT2FTZTV6ME5VTkw5M3JZSXo5bUszcmh2UjZsQ29NOGlEaVdWcG1YUnc0UFhwdSs0TE5rQkRDQ01Ka2h5cUdObkkxTElnY1FKc1lrcFphOUQ3dnRVV2xWdFB5Vm5zVithaXREV3lQMTdyemJHMCt5ZmZVRFdvYnBLSVFUMGNOR05hZkxRb3hQSlBTZUhNL1ljTXU3UzVvSUg0ZmM2VEJWUk9QUkNqMjh3T3p3TWVhNnJTUCIsInNpZ25hdHVyZVBheWxvYWQiOnsidXNlcklkIjoiNmYzMTBlY2MtNmY3My00YWVkLWEyY2YtNWQ3YTYwOWZkOTFhIiwiam9iSWQiOiIyMyIsImNsdXN0ZXJJZCI6IjU2ZjczZmI3LTM2NDQtNDRiNC1iMGZhLWJjMmYwNjQyZGZlZCIsIndvcmtzcGFjZU5hbWUiOiJjam9ha2ltY3Nsc3luYXBzZSIsImNvbXB1dGVOYW1lIjoicG9vbHNwYXJrM3MiLCJqb2JUeXBlIjoiU3BhcmtTZXJ2aWNlU2Vzc2lvbiJ9LCJmYWN0b3J5TG9jYXRpb24iOiJlYXN0dXMifQ.hQejpgqYfeuhaCyJbnCfvDhrwoGx47ELB_xKnW8KXpJOtmT4TeH1lM1dpta0M2flFC-oqPfYbhdIpvDEkgQuFoR3wAU1Wq-1s5Tw7SCyN40jm7bqHN7E7x8_16ZuRAiZaKF6kRpwX8fTuwOSd1PcfJY7i7zk0qPBY5wQh_0PUrEj1IBHLPYg6rWYNjeMxayV181b-Txir76ZHt24dm4A7SoG5X2wPfKjYEjFKeWYcvqLgXdPux3c127aoEjxVmTJzyrCC0SZlJ5egbQQ9ZrdFOFTVRj7afCx3Zg5O7CrjhaRJOghOYdmsLgE-xjNHQfrPNVpIp24lwlV0HClTNP70A\nspark.synapse.vegas.EnableProgressiveDownload, true\nspark.synapse.vegas.cacheSize, 0\nspark.synapse.vegas.useCache, true\nspark.synapse.workspace.name, cjoakimcslsynapse\nspark.tokenServiceEndpoint, tokenservice1.eastus.azuresynapse.net:443\nspark.ui.enhancement.enabled, true\nspark.ui.filters, org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter\nspark.ui.port, 0\nspark.ui.prometheus.enabled, true\nspark.unsafe.sorter.spill.reader.buffer.size, 1m\nspark.yarn.app.container.log.dir, /var/log/yarn-nm/userlogs/application_1643569089932_0002/container_1643569089932_0002_01_000001\nspark.yarn.app.id, application_1643569089932_0002\nspark.yarn.appMasterEnv.AZURE_SERVICE, Microsoft.ProjectArcadia\nspark.yarn.appMasterEnv.DOTNET_WORKER_2_0_0_DIR, /usr/local/bin/sparkdotnet/Microsoft.Spark.Worker/2.0.0\nspark.yarn.appMasterEnv.MMLSPARK_PLATFORM_INFO, synapse\nspark.yarn.appMasterEnv.PYSPARK_PYTHON, /home/trusted-service-user/cluster-env/env/bin/python\nspark.yarn.containerLauncherMaxThreads, 25\nspark.yarn.dist.archives, file:/opt/spark/R/lib/sparkr.zip#sparkr\nspark.yarn.dist.jars, local:///opt/livy/rsc-jars/livy-rsc.jar,local:///opt/livy/rsc-jars/livy-api.jar,local:///opt/livy/rsc-jars/netty-all-4.1.17.Final.jar,local:///opt/livy/repl_2.12-jars/livy-repl.jar,local:///opt/livy/repl_2.12-jars/livy-core.jar,local:///opt/livy/repl_2.12-jars/commons-codec-1.9.jar\nspark.yarn.dist.pyFiles, local:///opt/spark/python/lib/pyspark.zip,local:///opt/spark/python/lib/py4j-0.10.7-src.zip\nspark.yarn.executor.decommission.enabled, true\nspark.yarn.isPython, true\nspark.yarn.jars, local:///opt/spark/jars/*\nspark.yarn.maxAppAttempts, 1\nspark.yarn.populateHadoopClasspath.overWrite, true\nspark.yarn.preserve.staging.files, false\nspark.yarn.queue, default\nspark.yarn.scheduler.heartbeat.interval-ms, 1000\nspark.yarn.secondary.jars, local:///opt/livy/rsc-jars/livy-rsc.jar,local:///opt/livy/rsc-jars/livy-api.jar,local:///opt/livy/rsc-jars/netty-all-4.1.17.Final.jar,local:///opt/livy/repl_2.12-jars/livy-repl.jar,local:///opt/livy/repl_2.12-jars/livy-core.jar,local:///opt/livy/repl_2.12-jars/commons-codec-1.9.jar\nspark.yarn.stagingDir, wasbs://ab4ac815-c745-4a9a-85ec-dde7422c3794@139tqgao8koi70i65nhrafwa.blob.core.windows.net/user/trusted-service-user/\nspark.yarn.submit.waitAppCompletion, false\nspark.yarn.tags, livy-session-1-2p3Lx6Yr\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        }
      },
      "source": [
        "%%spark\n",
        "\n",
        "// Display the sorted entries of the Spark Conf \n",
        "\n",
        "val arrayConfig = spark.sparkContext.getConf.getAll\n",
        "for (conf <- arrayConfig.sorted)\n",
        "    println(conf._1 + \", \" + conf._2)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "poolspark3s",
              "session_id": 23,
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2022-01-30T20:09:11.5442326Z",
              "session_start_time": null,
              "execution_start_time": "2022-01-30T20:09:17.3032762Z",
              "execution_finish_time": "2022-01-30T20:09:17.4843419Z"
            },
            "text/plain": "StatementMeta(poolspark3s, 23, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "---\nAPPLICATION_WEB_PROXY_BASE\n/proxy/application_1643569089932_0002\n---\nAPP_SUBMIT_TIME_ENV\n1643573267565\n---\nAZURE_SERVICE\nMicrosoft.ProjectArcadia\n---\nCLASSPATH\n/usr/lib/library-manager/bin/libraries/scala/*:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/__spark_conf__:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/__spark_libs__/*:/opt/spark/jars/*:/usr/hdp/current/hadoop-yarn-nodemanager/../hadoop/conf:/usr/hdp/current/hadoop-client/*:/usr/hdp/current/hadoop-client/lib/*:/usr/hdp/current/hadoop-hdfs-client/*:/usr/hdp/current/hadoop-hdfs-client/lib/*:/usr/hdp/current/hadoop-yarn-client/*:/usr/hdp/current/hadoop-yarn-client/lib/*:/share/hadoop/mapreduce/*:/share/hadoop/mapreduce/lib/*:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/__spark_conf__/__hadoop_conf__\n---\nCONTAINER_ID\ncontainer_1643569089932_0002_01_000001\n---\nDOTNET_WORKER_2_0_0_DIR\n/usr/local/bin/sparkdotnet/Microsoft.Spark.Worker/2.0.0\n---\nHADOOP_CONF_DIR\n/usr/hdp/current/hadoop-yarn-nodemanager/../hadoop/conf\n---\nHADOOP_HOME\n/usr/hdp/current/hadoop-yarn-nodemanager/../hadoop\n---\nHADOOP_TOKEN_FILE_LOCATION\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/container_tokens\n---\nHADOOP_YARN_HOME\n/usr/hdp/5.0-50849917/hadoop-yarn\n---\nHOME\n/home/trusted-service-user\n---\nJAVA_HOME\n/usr/lib/jvm/java-8-openjdk-amd64\n---\nJVM_PID\n32132\n---\nLANG\nC.UTF-8\n---\nLD_LIBRARY_PATH\n/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-8-openjdk-amd64/jre/../lib/amd64:/usr/hdp/current/hadoop-client/lib/native:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64:/usr/lib/jvm/java-1.8.0-openjdk-amd64/jre/lib/amd64/server:\n---\nLIVY_SPARK_MAJOR_VERSION\n3\n---\nLOCAL_DIRS\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002\n---\nLOCAL_USER_DIRS\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/\n---\nLOGNAME\ntrusted-service-user\n---\nLOG_DIRS\n/var/log/yarn-nm/userlogs/application_1643569089932_0002/container_1643569089932_0002_01_000001\n---\nMALLOC_ARENA_MAX\n4\n---\nMMLSPARK_PLATFORM_INFO\nsynapse\n---\nNM_AUX_SERVICE_spark_shuffle\n\n---\nNM_HOST\nvm-7b077896\n---\nNM_HTTP_PORT\n8042\n---\nNM_PORT\n46851\n---\nPATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/usr/local/cuda-11.2/bin\n---\nPRELAUNCH_ERR\n/var/log/yarn-nm/userlogs/application_1643569089932_0002/container_1643569089932_0002_01_000001/prelaunch.err\n---\nPRELAUNCH_OUT\n/var/log/yarn-nm/userlogs/application_1643569089932_0002/container_1643569089932_0002_01_000001/prelaunch.out\n---\nPWD\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001\n---\nPYSPARK_GATEWAY_PORT\n40919\n---\nPYSPARK_GATEWAY_SECRET\nBUOV+WERVesdsE57GGvkY2wdTc8QAWZQpXmhat4ttRQ=\n---\nPYSPARK_PYTHON\n/home/trusted-service-user/cluster-env/env/bin/python\n---\nPYTHONHASHSEED\n0\n---\nPYTHONPATH\n/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/opt/spark/python/lib/pyspark.zip:/opt/spark/python/lib/py4j-0.10.7-src.zip:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/pyspark.zip:/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1643569089932_0002/container_1643569089932_0002_01_000001/py4j-0.10.7-src.zip\n---\nPYTHONUNBUFFERED\nYES\n---\nSHLVL\n2\n---\nSPARK_AUTH_SOCKET_TIMEOUT\n15\n---\nSPARK_BUFFER_SIZE\n65536\n---\nSPARK_HOME\n.\n---\nSPARK_USER\ntrusted-service-user\n---\nSPARK_YARN_STAGING_DIR\nwasbs://ab4ac815-c745-4a9a-85ec-dde7422c3794@139tqgao8koi70i65nhrafwa.blob.core.windows.net/user/trusted-service-user/trusted-service-user/.sparkStaging/application_1643569089932_0002\n---\nSYNAPSE_ENABLE_CONFIG_MERGE_RULE\ntrue\n---\nUSER\ntrusted-service-user\n---\n_\n/usr/lib/jvm/java-8-openjdk-amd64/bin/java"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        }
      },
      "source": [
        "%%pyspark\n",
        "\n",
        "# Display the Environment Variables\n",
        "\n",
        "import os \n",
        "\n",
        "for name in sorted(os.environ.keys()):\n",
        "    value = os.environ[name]\n",
        "    print(\"---\\n{}\\n{}\".format(name, value))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}